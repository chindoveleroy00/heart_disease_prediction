#!/usr/bin/env python3
"""
Script to fix or regenerate the corrupted PCA model
Run this from your project root directory
"""

import pickle
import joblib
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

def fix_pca_model():
    """Fix or regenerate the PCA model"""
    
    print("=== PCA MODEL RECOVERY ===")
    
    # Find the data directory
    data_dir = Path("data/models")
    if not data_dir.exists():
        print(f"âŒ Data directory not found: {data_dir}")
        return False
    
    pca_path = data_dir / "pca_model.pkl"
    
    # Check current PCA file
    if pca_path.exists():
        print(f"ğŸ“ Found PCA file: {pca_path}")
        print(f"ğŸ“Š File size: {pca_path.stat().st_size} bytes")
        
        # Try to load it
        try:
            with open(pca_path, 'rb') as f:
                pca_model = pickle.load(f)
            print("âœ… PCA model loads successfully - no fix needed!")
            return True
        except Exception as e:
            print(f"âŒ PCA model is corrupted: {e}")
            print("ğŸ”„ Attempting to fix...")
    else:
        print("âŒ PCA model file not found")
        print("ğŸ”„ Creating new PCA model...")
    
    # Try to load training data to create proper PCA
    training_data_paths = [
        "data/processed/featured_heart_data.csv",
        "data/processed/processed_heart_data.csv", 
        "data/raw/zimbabwe_heart_disease_data.csv"
    ]
    
    training_data = None
    for data_path in training_data_paths:
        path = Path(data_path)
        if path.exists():
            try:
                print(f"ğŸ“Š Loading training data from: {path}")
                training_data = pd.read_csv(path)
                print(f"âœ… Loaded data with shape: {training_data.shape}")
                break
            except Exception as e:
                print(f"âŒ Failed to load {path}: {e}")
                continue
    
    if training_data is not None:
        # Create proper PCA model from training data
        try:
            print("ğŸ”§ Creating PCA model from training data...")
            
            # Identify numerical columns for PCA
            numerical_cols = training_data.select_dtypes(include=[np.number]).columns.tolist()
            
            # Remove target column if it exists
            target_cols = ['target', 'heart_disease', 'prediction', 'label', 'class']
            for col in target_cols:
                if col in numerical_cols:
                    numerical_cols.remove(col)
            
            print(f"ğŸ“Š Using {len(numerical_cols)} numerical features for PCA")
            
            # Prepare data
            X = training_data[numerical_cols].fillna(0)
            
            # Standardize the data
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # Create PCA model with 5 components
            pca_model = PCA(n_components=5)
            pca_model.fit(X_scaled)
            
            # Save the PCA model
            with open(pca_path, 'wb') as f:
                pickle.dump(pca_model, f)
            
            print(f"âœ… PCA model saved successfully to {pca_path}")
            print(f"ğŸ“Š Explained variance ratio: {pca_model.explained_variance_ratio_}")
            print(f"ğŸ“Š Total explained variance: {sum(pca_model.explained_variance_ratio_):.2%}")
            
            # Verify the saved model
            with open(pca_path, 'rb') as f:
                test_pca = pickle.load(f)
            print("âœ… Saved PCA model verified successfully!")
            
            return True
            
        except Exception as e:
            print(f"âŒ Failed to create PCA from training data: {e}")
    
    # Fallback: Create basic PCA model
    print("ğŸ”„ Creating fallback PCA model...")
    try:
        # Create a basic PCA model with reasonable parameters
        pca_model = PCA(n_components=5)
        
        # Create representative dummy data (37 features as expected)
        # This matches the feature engineering in your model
        dummy_features = [
            'age', 'sex', 'ethnicity', 'family_history', 'previous_cardiac_events',
            'diabetes_status', 'hypertension', 'systolic_bp', 'diastolic_bp',
            'resting_heart_rate', 'height_cm', 'weight_kg', 'bmi',
            'total_cholesterol', 'hdl', 'ldl', 'fasting_glucose', 'hba1c',
            'smoking_status', 'alcohol_per_week', 'physical_activity_hours',
            'diet_quality', 'stress_level', 'chest_pain_type', 'exercise_induced_angina',
            'resting_ecg', 'max_heart_rate', 'st_depression', 'st_slope',
            'num_vessels', 'thalassemia', 'chol_ratio', 'bmi_category', 
            'age_decile', 'mean_arterial_pressure', 'rate_pressure_product', 
            'age_chol_interaction', 'bmi_hr_interaction'
        ]
        
        # Generate realistic dummy data
        np.random.seed(42)  # For reproducibility
        n_samples = 1000
        dummy_data = []
        
        for feature in dummy_features:
            if 'age' in feature.lower():
                data = np.random.normal(55, 15, n_samples)  # Age-like distribution
            elif 'bp' in feature.lower() or 'pressure' in feature.lower():
                data = np.random.normal(130, 20, n_samples)  # Blood pressure-like
            elif 'cholesterol' in feature.lower():
                data = np.random.normal(200, 40, n_samples)  # Cholesterol-like
            elif 'heart_rate' in feature.lower():
                data = np.random.normal(70, 15, n_samples)  # Heart rate-like
            elif feature in ['sex', 'ethnicity', 'family_history', 'diabetes_status', 'hypertension']:
                data = np.random.binomial(1, 0.5, n_samples)  # Binary features
            else:
                data = np.random.normal(0, 1, n_samples)  # Standard normal
            
            dummy_data.append(data)
        
        dummy_data = np.array(dummy_data).T  # Shape: (n_samples, n_features)
        
        # Fit PCA
        pca_model.fit(dummy_data)
        
        # Save the model
        with open(pca_path, 'wb') as f:
            pickle.dump(pca_model, f)
        
        print(f"âœ… Fallback PCA model created and saved to {pca_path}")
        print("âš ï¸  Note: This is a basic PCA model. For best results, retrain with actual data.")
        
        # Verify
        with open(pca_path, 'rb') as f:
            test_pca = pickle.load(f)
        print("âœ… Fallback PCA model verified successfully!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to create fallback PCA model: {e}")
        return False

def main():
    """Main function"""
    print("Starting PCA model recovery...")
    
    if fix_pca_model():
        print("\nğŸ‰ SUCCESS! PCA model has been fixed/created.")
        print("You can now run your Streamlit app without PCA errors.")
    else:
        print("\nâŒ FAILED to fix PCA model.")
        print("The app will still work but may have reduced accuracy.")
        print("Consider retraining the PCA model with proper training data.")

if __name__ == "__main__":
    main()